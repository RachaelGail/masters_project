{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee79076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # only use GPU memory that we need, not allocate all the GPU memory\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], enable=True)\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from os import walk \n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "import keras as keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import Recall, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0101f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPAM_1_FILEPATH = 'UniversityProject_SpamFilter/01_Processing/spam_assassin_corpus/spam_1'\n",
    "SPAM_2_FILEPATH = 'UniversityProject_SpamFilter/01_Processing/spam_assassin_corpus/spam_2'\n",
    "HAM_1_FILEPATH = 'UniversityProject_SpamFilter/01_Processing/spam_assassin_corpus/ham_1'\n",
    "HAM_2_FILEPATH = 'UniversityProject_SpamFilter/01_Processing/spam_assassin_corpus/ham_2'\n",
    "\n",
    "SPAM_CAT = 1\n",
    "HAM_CAT = 0\n",
    "\n",
    "\n",
    "SEQUENCE_LENGTH = 100 # the length of all sequences (number of words per sample)\n",
    "EMBEDDING_SIZE = 100  # Using 100-Dimensional GloVe embedding vectors\n",
    "TEST_SIZE = 0.25 # ratio of testing set\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10 # number of epochs\n",
    "\n",
    "label2int = {\"ham\": 0, \"spam\": 1}\n",
    "int2label = {0: \"ham\", 1: \"spam\"}\n",
    "\n",
    "CUSTOM_FONT = 'UniversityProject_SpamFilter/wordcloud_resources/OpenSansCondensed-Bold.ttf'\n",
    "WORD_CLOUD = 'UniversityProject_SpamFilter/wordcloud_resources/word_cloud.png'\n",
    "THUMBS_UP = 'UniversityProject_SpamFilter/wordcloud_resources/thumbs-up.png'\n",
    "THUMBS_DOWN = 'UniversityProject_SpamFilter/wordcloud_resources/thumbs-down.png'\n",
    "X_ICON = 'UniversityProject_SpamFilter/wordcloud_resources/x-icon.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33533b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_body_generator(path): \n",
    "                                    #walk provides a tuple \n",
    "    for root, dirnames, filenames, in walk(path):\n",
    "        for file_name in filenames:\n",
    "            \n",
    "            filepath = join(root, file_name)\n",
    "            stream = open(filepath, encoding='latin-1')\n",
    "            is_body= False\n",
    "            lines = []\n",
    "            \n",
    "            #extracts email body \n",
    "            for line in stream: \n",
    "                if is_body: \n",
    "                    lines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    is_body = True\n",
    "\n",
    "            stream.close()\n",
    "\n",
    "            email_body = '\\n'.join(lines)\n",
    "            \n",
    "            #loops over the file in the directory and returns the file name and associated email body \n",
    "            yield file_name, email_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6bf95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_directory(path, classification):\n",
    "    rows = []\n",
    "    row_names = []\n",
    "    \n",
    "    for file_name, email_body in email_body_generator(path):\n",
    "        rows.append({'MESSAGE': email_body, 'CATEGORY': classification})\n",
    "        row_names.append(file_name) \n",
    "    \n",
    "    return pd.DataFrame(rows, index=row_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4451845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_emails = dataframe_from_directory(SPAM_1_FILEPATH, SPAM_CAT)\n",
    "spam_emails = spam_emails.append(dataframe_from_directory(SPAM_2_FILEPATH, SPAM_CAT))\n",
    "ham_emails = dataframe_from_directory(HAM_1_FILEPATH, HAM_CAT)\n",
    "ham_emails = ham_emails.append(dataframe_from_directory(HAM_2_FILEPATH, HAM_CAT))\n",
    "data = pd.concat([spam_emails, ham_emails])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9237d343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cmds', 'cmds', 'cmds'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.MESSAGE.str.len() == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aebcca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['cmds'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10cb667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00249.5f45607c1bffe89f60ba1ec9f878039a</th>\n",
       "      <td>Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00373.ebe8670ac56b04125c25100a36ab0510</th>\n",
       "      <td>ATTENTION: This is a MUST for ALL Computer Use...</td>\n",
       "      <td>1</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00214.1367039e50dc6b7adb0f2aa8aba83216</th>\n",
       "      <td>This is a multi-part message in MIME format.\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>6691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00210.050ffd105bd4e006771ee63cabc59978</th>\n",
       "      <td>IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00033.9babb58d9298daa2963d4f514193d7d6</th>\n",
       "      <td>This is the bottom line.  If you can GIVE AWAY...</td>\n",
       "      <td>1</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00609.dd49926ce94a1ea328cce9b62825bc97</th>\n",
       "      <td>I'm one of the 30,000 but it's not working ver...</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00957.e0b56b117f3ec5f85e432a9d2a47801f</th>\n",
       "      <td>Damien Morton quoted:\\n\\n&gt;W3C approves HTML 4 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01127.841233b48eceb74a825417d8d918abf8</th>\n",
       "      <td>On Mon, 2002-07-22 at 06:50, che wrote:\\n\\n\\n\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01178.5c977dff972cd6eef64d4173b90307f0</th>\n",
       "      <td>Once upon a time, Manfred wrote :\\n\\n\\n\\n&gt; I w...</td>\n",
       "      <td>0</td>\n",
       "      <td>1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00747.352d424267d36975a7b40b85ffd0885e</th>\n",
       "      <td>If you run Pick, and then use the \"New FTOC\" b...</td>\n",
       "      <td>0</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5796 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  MESSAGE  \\\n",
       "00249.5f45607c1bffe89f60ba1ec9f878039a  Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...   \n",
       "00373.ebe8670ac56b04125c25100a36ab0510  ATTENTION: This is a MUST for ALL Computer Use...   \n",
       "00214.1367039e50dc6b7adb0f2aa8aba83216  This is a multi-part message in MIME format.\\n...   \n",
       "00210.050ffd105bd4e006771ee63cabc59978  IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...   \n",
       "00033.9babb58d9298daa2963d4f514193d7d6  This is the bottom line.  If you can GIVE AWAY...   \n",
       "...                                                                                   ...   \n",
       "00609.dd49926ce94a1ea328cce9b62825bc97  I'm one of the 30,000 but it's not working ver...   \n",
       "00957.e0b56b117f3ec5f85e432a9d2a47801f  Damien Morton quoted:\\n\\n>W3C approves HTML 4 ...   \n",
       "01127.841233b48eceb74a825417d8d918abf8  On Mon, 2002-07-22 at 06:50, che wrote:\\n\\n\\n\\...   \n",
       "01178.5c977dff972cd6eef64d4173b90307f0  Once upon a time, Manfred wrote :\\n\\n\\n\\n> I w...   \n",
       "00747.352d424267d36975a7b40b85ffd0885e  If you run Pick, and then use the \"New FTOC\" b...   \n",
       "\n",
       "                                        CATEGORY  length  \n",
       "00249.5f45607c1bffe89f60ba1ec9f878039a         1     612  \n",
       "00373.ebe8670ac56b04125c25100a36ab0510         1    1298  \n",
       "00214.1367039e50dc6b7adb0f2aa8aba83216         1    6691  \n",
       "00210.050ffd105bd4e006771ee63cabc59978         1    1141  \n",
       "00033.9babb58d9298daa2963d4f514193d7d6         1    1795  \n",
       "...                                          ...     ...  \n",
       "00609.dd49926ce94a1ea328cce9b62825bc97         0     953  \n",
       "00957.e0b56b117f3ec5f85e432a9d2a47801f         0     257  \n",
       "01127.841233b48eceb74a825417d8d918abf8         0     393  \n",
       "01178.5c977dff972cd6eef64d4173b90307f0         0    1434  \n",
       "00747.352d424267d36975a7b40b85ffd0885e         0     866  \n",
       "\n",
       "[5796 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['length']=data['MESSAGE'].apply(len)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f9018f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_ids = range(0, len(data.index))\n",
    "data['Doc_ID'] = documents_ids\n",
    "data['File_Name'] = data.index\n",
    "data = data.set_index('Doc_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "740c18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_stopwords = set(text.ENGLISH_STOP_WORDS)\n",
    "gensim_stopwords = set(gensim.parsing.preprocessing.STOPWORDS)\n",
    "nltk_stop_words = stopwords.words('english')\n",
    "\n",
    "gensim_and_sklearn = sklearn_stopwords.union(gensim_stopwords)\n",
    "libary_stopwords = gensim_and_sklearn.union(nltk_stop_words)\n",
    "\n",
    "all_stop_words = {'url', 'http', '\\n', '[html', 'html', 'tr', 'td', 'https', 'br', 'ign', 'err', 'mpt','[', ']' }\n",
    "all_stop_words.update(libary_stopwords)\n",
    "\n",
    "capital_sw = [each_string.title() for each_string in all_stop_words]\n",
    "uppercase_sw = [each_string.upper() for each_string in all_stop_words]\n",
    "\n",
    "all_stop_words.update(capital_sw)\n",
    "all_stop_words.update(uppercase_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac9db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_msg_nohtml(message, #stemmer = PorterStemmer(),\n",
    "                  stop_words = set(all_stop_words)): \n",
    "    \n",
    "    # Remove HTML tags \n",
    "    soup = BeautifulSoup(message, 'html.parser')\n",
    "    cleaned_text = soup.get_text()\n",
    "    \n",
    "    #Converts to lower case and splots up  the individual words\n",
    "    words = word_tokenize(cleaned_text)\n",
    "    \n",
    "    filtered_words = []\n",
    "    \n",
    "    for word in words: \n",
    "        if word not in stop_words and word.isalpha():\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b588a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachaeldoherty/opt/anaconda3/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.post-gazette.com/columnists/20020905brian5\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nested_list = data.MESSAGE.apply(clean_msg_nohtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d074d577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Doc_ID\n",
       "0       [Dear, Homeowner, Rates, lowest, point, years,...\n",
       "1       [ATTENTION, Users, Package, Deal, Norton, Syst...\n",
       "2       [message, MIME, format, dare, Try, better, ann...\n",
       "3       [IMPORTANT, INFORMATION, new, domain, names, f...\n",
       "4       [line, AWAY, CD, FREE, people, like, month, le...\n",
       "                              ...                        \n",
       "5791    [working, week, TES, updates, servers, syncing...\n",
       "5792    [Damien, Morton, quoted, approves, able, feeli...\n",
       "5793    [Mon, che, wrote, thats, correct, lines, added...\n",
       "5794    [time, Manfred, wrote, like, install, RPM, tri...\n",
       "5795    [run, Pick, use, New, FTOC, button, messages, ...\n",
       "Name: MESSAGE, Length: 5796, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d17ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_id_SPAM = data[data.CATEGORY ==1].index\n",
    "docs_id_HAM = data[data.CATEGORY ==0].index\n",
    "\n",
    "nested_list_HAM = nested_list.loc[docs_id_HAM]\n",
    "nested_list_SPAM = nested_list.loc[docs_id_SPAM]\n",
    "flat_list_HAM = [item for sublist in nested_list_HAM for item in sublist]\n",
    "\n",
    "#total number of unique words in the non spam messages\n",
    "HAM_words = pd.Series(flat_list_HAM).value_counts() \n",
    "flat_list_SPAM = [item for sublist in nested_list_SPAM for item in sublist]\n",
    "\n",
    "#total number of unique words in the spam messages\n",
    "SPAM_words = pd.Series(flat_list_SPAM).value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acd48cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(SPAM_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "490287da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email          1955\n",
       "list           1312\n",
       "money          1185\n",
       "business       1181\n",
       "information    1177\n",
       "               ... \n",
       "ttract            1\n",
       "KIFF              1\n",
       "HOLD              1\n",
       "Knife             1\n",
       "appearsON         1\n",
       "Length: 24302, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPAM_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203bbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "463b880c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Subject: home loans just got better !  free se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Subject: high - quality affordable logos  corp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Subject: your logo and visual identity from us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Subject: all graphics software available , che...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Subject: re : change of plans  hello you two ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  1\n",
       "1    Subject: naturally irresistible your corporate...  1\n",
       "2    Subject: the stock trading gunslinger  fanny i...  1\n",
       "3    Subject: unbelievable new homes made easy  im ...  1\n",
       "4    Subject: 4 color printing special  request add...  1\n",
       "5    Subject: do not have money , get software cds ...  1\n",
       "..                                                 ... ..\n",
       "496  Subject: home loans just got better !  free se...  1\n",
       "497  Subject: high - quality affordable logos  corp...  1\n",
       "498  Subject: your logo and visual identity from us...  1\n",
       "499  Subject: all graphics software available , che...  1\n",
       "500  Subject: re : change of plans  hello you two ,...  1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification mlp model for the abalone dataset\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# load dataset\n",
    "dataframe = read_csv('emails.csv', header=None)\n",
    "dataframe= dataframe[1::]\n",
    "dataset = dataframe.values\n",
    "dataframe[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bf63ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split into input (X) and output (y) variables\n",
    "# X, y = dataset[:, 1:-1], dataset[:, -1]\n",
    "# X = X.astype('int') \n",
    "# y = y.astype('float')\n",
    "# n_features = X.shape[1]\n",
    "# # encode strings to integer\n",
    "# y = LabelEncoder().fit_transform(y)\n",
    "# n_class = len(unique(y))\n",
    "# # split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# # define the keras model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
    "# model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "# model.add(Dense(n_class, activation='softmax'))\n",
    "# # compile the keras model\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "# # fit the keras model on the dataset\n",
    "# model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=2)\n",
    "# # evaluate on test set\n",
    "# yhat = model.predict(X_test)\n",
    "# yhat = argmax(yhat, axis=-1).astype('int')\n",
    "# acc = accuracy_score(y_test, yhat)\n",
    "# print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d93b216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58d9c904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Epoch 1/150\n",
      "120/120 - 0s - loss: 0.8873 - dense_2_loss: 0.2206 - dense_3_loss: 0.6667 - 483ms/epoch - 4ms/step\n",
      "Epoch 2/150\n",
      "120/120 - 0s - loss: 0.8198 - dense_2_loss: 0.1949 - dense_3_loss: 0.6250 - 84ms/epoch - 703us/step\n",
      "Epoch 3/150\n",
      "120/120 - 0s - loss: 0.7837 - dense_2_loss: 0.1863 - dense_3_loss: 0.5974 - 84ms/epoch - 696us/step\n",
      "Epoch 4/150\n",
      "120/120 - 0s - loss: 0.7639 - dense_2_loss: 0.1843 - dense_3_loss: 0.5796 - 81ms/epoch - 678us/step\n",
      "Epoch 5/150\n",
      "120/120 - 0s - loss: 0.7527 - dense_2_loss: 0.1840 - dense_3_loss: 0.5687 - 75ms/epoch - 623us/step\n",
      "Epoch 6/150\n",
      "120/120 - 0s - loss: 0.7461 - dense_2_loss: 0.1839 - dense_3_loss: 0.5622 - 72ms/epoch - 597us/step\n",
      "Epoch 7/150\n",
      "120/120 - 0s - loss: 0.7425 - dense_2_loss: 0.1839 - dense_3_loss: 0.5586 - 72ms/epoch - 604us/step\n",
      "Epoch 8/150\n",
      "120/120 - 0s - loss: 0.7405 - dense_2_loss: 0.1839 - dense_3_loss: 0.5566 - 73ms/epoch - 608us/step\n",
      "Epoch 9/150\n",
      "120/120 - 0s - loss: 0.7394 - dense_2_loss: 0.1839 - dense_3_loss: 0.5555 - 75ms/epoch - 629us/step\n",
      "Epoch 10/150\n",
      "120/120 - 0s - loss: 0.7388 - dense_2_loss: 0.1839 - dense_3_loss: 0.5549 - 72ms/epoch - 598us/step\n",
      "Epoch 11/150\n",
      "120/120 - 0s - loss: 0.7386 - dense_2_loss: 0.1840 - dense_3_loss: 0.5547 - 74ms/epoch - 617us/step\n",
      "Epoch 12/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 73ms/epoch - 606us/step\n",
      "Epoch 13/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 83ms/epoch - 691us/step\n",
      "Epoch 14/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 74ms/epoch - 620us/step\n",
      "Epoch 15/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 71ms/epoch - 594us/step\n",
      "Epoch 16/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 74ms/epoch - 614us/step\n",
      "Epoch 17/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 91ms/epoch - 762us/step\n",
      "Epoch 18/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 75ms/epoch - 626us/step\n",
      "Epoch 19/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 85ms/epoch - 706us/step\n",
      "Epoch 20/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 688us/step\n",
      "Epoch 21/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 75ms/epoch - 626us/step\n",
      "Epoch 22/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 77ms/epoch - 638us/step\n",
      "Epoch 23/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 72ms/epoch - 599us/step\n",
      "Epoch 24/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 73ms/epoch - 608us/step\n",
      "Epoch 25/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 77ms/epoch - 642us/step\n",
      "Epoch 26/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 79ms/epoch - 654us/step\n",
      "Epoch 27/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 79ms/epoch - 661us/step\n",
      "Epoch 28/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 96ms/epoch - 799us/step\n",
      "Epoch 29/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 692us/step\n",
      "Epoch 30/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 74ms/epoch - 613us/step\n",
      "Epoch 31/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 72ms/epoch - 597us/step\n",
      "Epoch 32/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 73ms/epoch - 606us/step\n",
      "Epoch 33/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 72ms/epoch - 598us/step\n",
      "Epoch 34/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 73ms/epoch - 609us/step\n",
      "Epoch 35/150\n",
      "120/120 - 0s - loss: 0.7383 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 80ms/epoch - 670us/step\n",
      "Epoch 36/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 75ms/epoch - 628us/step\n",
      "Epoch 37/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 72ms/epoch - 604us/step\n",
      "Epoch 38/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 73ms/epoch - 608us/step\n",
      "Epoch 39/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 74ms/epoch - 614us/step\n",
      "Epoch 40/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 71ms/epoch - 595us/step\n",
      "Epoch 41/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 72ms/epoch - 596us/step\n",
      "Epoch 42/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 73ms/epoch - 612us/step\n",
      "Epoch 43/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 74ms/epoch - 615us/step\n",
      "Epoch 44/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 73ms/epoch - 612us/step\n",
      "Epoch 45/150\n",
      "120/120 - 0s - loss: 0.7383 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 73ms/epoch - 612us/step\n",
      "Epoch 46/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 79ms/epoch - 654us/step\n",
      "Epoch 47/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 72ms/epoch - 602us/step\n",
      "Epoch 48/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 72ms/epoch - 599us/step\n",
      "Epoch 49/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 72ms/epoch - 600us/step\n",
      "Epoch 50/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 73ms/epoch - 607us/step\n",
      "Epoch 51/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 73ms/epoch - 610us/step\n",
      "Epoch 52/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 73ms/epoch - 605us/step\n",
      "Epoch 53/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 75ms/epoch - 622us/step\n",
      "Epoch 54/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 73ms/epoch - 607us/step\n",
      "Epoch 55/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 73ms/epoch - 608us/step\n",
      "Epoch 56/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 72ms/epoch - 604us/step\n",
      "Epoch 57/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 72ms/epoch - 600us/step\n",
      "Epoch 58/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 709us/step\n",
      "Epoch 59/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 707us/step\n",
      "Epoch 60/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 709us/step\n",
      "Epoch 61/150\n",
      "120/120 - 0s - loss: 0.7386 - dense_2_loss: 0.1841 - dense_3_loss: 0.5546 - 85ms/epoch - 705us/step\n",
      "Epoch 62/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 712us/step\n",
      "Epoch 63/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 93ms/epoch - 776us/step\n",
      "Epoch 64/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 81ms/epoch - 678us/step\n",
      "Epoch 65/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 709us/step\n",
      "Epoch 66/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 692us/step\n",
      "Epoch 67/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 86ms/epoch - 717us/step\n",
      "Epoch 68/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 693us/step\n",
      "Epoch 69/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 701us/step\n",
      "Epoch 70/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 694us/step\n",
      "Epoch 71/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 86ms/epoch - 713us/step\n",
      "Epoch 72/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 695us/step\n",
      "Epoch 73/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 691us/step\n",
      "Epoch 74/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 83ms/epoch - 693us/step\n",
      "Epoch 75/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 696us/step\n",
      "Epoch 76/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 85ms/epoch - 707us/step\n",
      "Epoch 77/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 86ms/epoch - 713us/step\n",
      "Epoch 78/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5544 - 83ms/epoch - 696us/step\n",
      "Epoch 79/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 692us/step\n",
      "Epoch 80/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 83ms/epoch - 694us/step\n",
      "Epoch 81/150\n",
      "120/120 - 0s - loss: 0.7386 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 82ms/epoch - 681us/step\n",
      "Epoch 82/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 692us/step\n",
      "Epoch 83/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 700us/step\n",
      "Epoch 84/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 707us/step\n",
      "Epoch 85/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 689us/step\n",
      "Epoch 86/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 699us/step\n",
      "Epoch 87/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 703us/step\n",
      "Epoch 88/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 690us/step\n",
      "Epoch 89/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 695us/step\n",
      "Epoch 90/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 708us/step\n",
      "Epoch 91/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 82ms/epoch - 682us/step\n",
      "Epoch 92/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 695us/step\n",
      "Epoch 93/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 82ms/epoch - 679us/step\n",
      "Epoch 94/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 689us/step\n",
      "Epoch 95/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 82ms/epoch - 687us/step\n",
      "Epoch 96/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 85ms/epoch - 708us/step\n",
      "Epoch 97/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 693us/step\n",
      "Epoch 98/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 688us/step\n",
      "Epoch 99/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 82ms/epoch - 682us/step\n",
      "Epoch 100/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 700us/step\n",
      "Epoch 101/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 694us/step\n",
      "Epoch 102/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 84ms/epoch - 701us/step\n",
      "Epoch 103/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 84ms/epoch - 700us/step\n",
      "Epoch 104/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 696us/step\n",
      "Epoch 105/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 690us/step\n",
      "Epoch 106/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 90ms/epoch - 746us/step\n",
      "Epoch 107/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 84ms/epoch - 697us/step\n",
      "Epoch 108/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 689us/step\n",
      "Epoch 109/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 694us/step\n",
      "Epoch 110/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 696us/step\n",
      "Epoch 111/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 83ms/epoch - 691us/step\n",
      "Epoch 112/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 705us/step\n",
      "Epoch 113/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 702us/step\n",
      "Epoch 114/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 81ms/epoch - 675us/step\n",
      "Epoch 115/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 84ms/epoch - 700us/step\n",
      "Epoch 116/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 707us/step\n",
      "Epoch 117/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 85ms/epoch - 712us/step\n",
      "Epoch 118/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5544 - 86ms/epoch - 717us/step\n",
      "Epoch 119/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 701us/step\n",
      "Epoch 120/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 698us/step\n",
      "Epoch 121/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 82ms/epoch - 687us/step\n",
      "Epoch 122/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 81ms/epoch - 676us/step\n",
      "Epoch 123/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 694us/step\n",
      "Epoch 124/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 692us/step\n",
      "Epoch 125/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5545 - 84ms/epoch - 703us/step\n",
      "Epoch 126/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 691us/step\n",
      "Epoch 127/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 706us/step\n",
      "Epoch 128/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 692us/step\n",
      "Epoch 129/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 695us/step\n",
      "Epoch 130/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 695us/step\n",
      "Epoch 131/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 708us/step\n",
      "Epoch 132/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 85ms/epoch - 705us/step\n",
      "Epoch 133/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 698us/step\n",
      "Epoch 134/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 688us/step\n",
      "Epoch 135/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 698us/step\n",
      "Epoch 136/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 85ms/epoch - 710us/step\n",
      "Epoch 137/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 690us/step\n",
      "Epoch 138/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 84ms/epoch - 703us/step\n",
      "Epoch 139/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 84ms/epoch - 696us/step\n",
      "Epoch 140/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 85ms/epoch - 709us/step\n",
      "Epoch 141/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 696us/step\n",
      "Epoch 142/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 704us/step\n",
      "Epoch 143/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 692us/step\n",
      "Epoch 144/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 83ms/epoch - 690us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 84ms/epoch - 703us/step\n",
      "Epoch 146/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 84ms/epoch - 701us/step\n",
      "Epoch 147/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 84ms/epoch - 697us/step\n",
      "Epoch 148/150\n",
      "120/120 - 0s - loss: 0.7385 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 83ms/epoch - 695us/step\n",
      "Epoch 149/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1839 - dense_3_loss: 0.5544 - 81ms/epoch - 678us/step\n",
      "Epoch 150/150\n",
      "120/120 - 0s - loss: 0.7384 - dense_2_loss: 0.1840 - dense_3_loss: 0.5545 - 82ms/epoch - 684us/step\n",
      "MAE: 0.361\n",
      "Accuracy: 0.769\n"
     ]
    }
   ],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X, y = dataset[:, 1:-1], dataset[:, -1]\n",
    "X, y = X.astype('float'), y.astype('float')\n",
    "n_features = X.shape[1]\n",
    "# encode strings to integer\n",
    "y_class = LabelEncoder().fit_transform(y)\n",
    "n_class = len(unique(y_class))\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test, y_train_class, y_test_class = train_test_split(X, y, y_class, test_size=0.33, random_state=1)\n",
    "# input\n",
    "visible = Input(shape=(n_features,))\n",
    "hidden1 = Dense(20, activation='relu', kernel_initializer='he_normal')(visible)\n",
    "hidden2 = Dense(10, activation='relu', kernel_initializer='he_normal')(hidden1)\n",
    "# regression output\n",
    "out_reg = Dense(1, activation='linear')(hidden2)\n",
    "# classification output\n",
    "out_clas = Dense(n_class, activation='softmax')(hidden2)\n",
    "# define model\n",
    "model = Model(inputs=visible, outputs=[out_reg, out_clas])\n",
    "# compile the keras model\n",
    "model.compile(loss=['mse','sparse_categorical_crossentropy'], optimizer='adam')\n",
    "# plot graph of model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, [y_train,y_train_class], epochs=150, batch_size=32, verbose=2)\n",
    "# make predictions on test set\n",
    "yhat1, yhat2 = model.predict(X_test)\n",
    "# calculate error for regression model\n",
    "error = mean_absolute_error(y_test, yhat1)\n",
    "print('MAE: %.3f' % error)\n",
    "# evaluate accuracy for classification model\n",
    "yhat2 = argmax(yhat2, axis=-1).astype('int')\n",
    "acc = accuracy_score(y_test_class, yhat2)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56036d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb457f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294235a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21decfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b902ade6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad21435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb57efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10207b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e33208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bacdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e33745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc84b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3b163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4e272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a879b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbbd64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261aff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
